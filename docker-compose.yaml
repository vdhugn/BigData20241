# version: '3'

services:
  # HDFS cluster
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    ports:
      - 9870:9870
      - 9000:9000
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop/hadoop.env
    restart: always
    networks:
      real_estate_net:
    volumes:
      - hadoop_namenode:/hadoop/dfs/name

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    depends_on:
      - namenode
    env_file:
      - ./hadoop/hadoop.env
    restart: always
    networks:
      real_estate_net:
    volumes:
      - hadoop_datanode:/hadoop/dfs/data

  hue:
    image: bde2020/hdfs-filebrowser:3.11
    container_name: hue
    ports:
      - 8088:8088
    environment:
      NAMENODE_HOST: namenode
    networks:
      real_estate_net:

  # Kafka cluster
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      real_estate_net:
    healthcheck:
      test: ['CMD', 'bash', '-c', "echo 'ruok' | nc localhost 2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  broker:
    image: confluentinc/cp-server:7.4.0
    container_name: broker
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    ports:
      - "9092:9092"
    networks:
      real_estate_net:
    healthcheck:
      test: ["CMD", "bash", "-c", 'nc -z localhost 9092']
      interval: 10s
      timeout: 5s
      retries: 5

  # Spark cluster
  spark-master:
    image: bde2020/spark-master:2.1.0-hadoop2.8-hive-java8
    container_name: spark-master
    ports:
      - 8080:8080
      - 7077:7077
    env_file:
      - ./hadoop/hadoop.env
    networks:
      real_estate_net:

  spark-worker:
    image: bde2020/spark-worker:2.1.0-hadoop2.8-hive-java8
    depends_on:
      - spark-master
    container_name: spark-worker
    environment:
      SPARK_MASTER: spark://spark-master:7077
      SPARK_MODE: worker
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
    ports:
      - 8081:8081
    env_file:
      - ./hadoop/hadoop.env
    networks:
      real_estate_net:

  spark-notebook:
    image: bde2020/spark-notebook:2.1.0-hadoop2.8-hive
    container_name: spark-notebook
    env_file:
      - ./hadoop/hadoop.env
    ports:
      - 9090:9090
    networks:
      real_estate_net:

  # Other
  database:
    image: postgres:14
    container_name: postgresDB
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=spark
    ports:
      - 5432:5432
    networks:
      real_estate_net:
    volumes:
      - db:/var/lib/postgresql/data

  superset:
    image: apache/superset:latest
    container_name: superset
    environment:
      - SUPERSET_SECRET_KEY=secret
      - SUPERSET_DATABASE_URL=postgresql+psycopg2://user:password@postgresDB:5432/spark
    restart: unless-stopped
    ports:
      - 8888:8888
    command:
      - /bin/bash
      - -c
      - |
        superset db upgrade &&
        superset fab create-admin \
          --username admin \
          --password admin \
          --firstname Admin \
          --lastname User \
          --email admin@superset.com &&
        superset init &&
        superset run -h 0.0.0.0 -p 8888
    networks:
      real_estate_net:
    volumes:
      - superset_data:/app/superset_home

networks:
  real_estate_net:

volumes:
  postgres-db-volume:
  hadoop_namenode:
  hadoop_datanode:
  db:
  superset_data: